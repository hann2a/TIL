대분류,중분류,소분류,설명
텍스트 파운데이션 모델 살펴보기,텍스트 파운데이션 모델(LLM)이란?,정의,"대량의 데이터를 기반으로 사전 학습되며, 다양한 작업에 범용적으로 활용 가능한 기초(foundation) 역할을 하는 대규모 AI 모델"
텍스트 파운데이션 모델 살펴보기,텍스트 파운데이션 모델(LLM)이란?,3가지 구성요소 (1) 빅데이터,"인터넷에 존재하는 데이터 수가 기하급수적으로 증가하며 (예: 2025년 175 ZB 예상), 딥러닝 기반 AI 모델의 성능이 학습 데이터량에 비례하여 증가함"
텍스트 파운데이션 모델 살펴보기,텍스트 파운데이션 모델(LLM)이란?,3가지 구성요소 (2) 자기 학습 알고리즘,"사람이 정답을 알려줄 필요 없이 학습하며, 예시로 '다음 토큰 예측(Next token prediction)'을 통해 텍스트 데이터로부터 학습 데이터를 생성함 (Self-supervised Learning)"
텍스트 파운데이션 모델 살펴보기,텍스트 파운데이션 모델(LLM)이란?,3가지 구성요소 (3) 어텐션 기반 트랜스포머 모델,"더 많은 데이터를 학습할 수 있는 인공신경망 구조이며, 어텐션 메커니즘을 기반으로 함"
텍스트 파운데이션 모델 살펴보기,텍스트 파운데이션 모델(LLM)이란?,특징 (1) 규모의 법칙 (Scaling Law),"더 많은 데이터, 더 큰 모델, 긴 학습을 통해 더 좋은 성능을 얻을 수 있음"
텍스트 파운데이션 모델 살펴보기,텍스트 파운데이션 모델(LLM)이란?,특징 (2) 창발성 (Emergent Property),"특정 모델 규모를 넘어서면 모델에서 갑자기 발현되는 능력으로, 인-컨텍스트 학습(In-context Learning)이나 추론(Reasoning) 능력 등이 이에 해당함"
텍스트 파운데이션 모델 살펴보기,거대 언어 모델 예시,폐쇄형 (Closed) 모델,"OpenAI(ChatGPT), Anthropic(Claude), Google(Gemini) 등이 있으며, 일반적으로 우수한 성능과 최신 지식을 제공하지만, 사용 시 비용이 발생하고 출력 정보가 제한적일 수 있음"
텍스트 파운데이션 모델 살펴보기,거대 언어 모델 예시,개방형 (Open sourced) 모델,"Meta(LLaMA), Google(Gemma), Alibaba(Qwen) 등이 있으며, 무료 다운로드 및 사용이 가능하고 모델 구조/소스코드가 공개되어 있지만, 충분한 계산 자원이 필요하고 폐쇄형 모델 대비 성능이 낮을 수 있음"
거대 언어 모델의 학습,GPT-3: 거대 언어 모델의 시초,배경,"1750억 개의 매개변수를 가진 가장 큰 버전의 모델로, 기존 언어 모델 대비 최소 10배 이상 큼"
거대 언어 모델의 학습,GPT-3: 거대 언어 모델의 시초,능력,"본격적으로 인-컨텍스트 학습 능력이 나타나기 시작한 모델"
거대 언어 모델의 학습,정렬 (Alignment) 학습,정의,"거대 언어 모델의 출력이 사용자의 의도와 가치를 반영하도록 하는 것"
거대 언어 모델의 학습,정렬 (Alignment) 학습,2-1. 지시 학습 (Instruction Tuning),"주어진 지시에 대해 어떤 응답을 생성해야 하는지 학습하는 과정으로, 지도 학습(Supervised Fine-Tuning, SFT)과 동일하며, FLAN/T0 모델 등에서 파운데이션 모델을 다양한 지시 기반 입력으로 추가 학습시킴"
거대 언어 모델의 학습,정렬 (Alignment) 학습,2-2. 선호 학습 (Preference Learning),"다양한 응답 중 사람이 선호하는 응답을 생성하도록 추가 학습하는 과정이며, 응답 간 선호도는 사람이 제공함"
거대 언어 모델의 학습,정렬 (Alignment) 학습,InstructGPT의 학습 방법 (RLHF),"지시 학습을 통해 텍스트 파운데이션 모델(예: GPT-3)을 추가 학습하고, 사람의 선호 데이터를 수집하여 보상 모델(Reward Model, RM)을 학습시킨 뒤, 보상이 높은 응답을 생성하도록 강화 학습을 통해 추가 학습함"
거대 언어 모델의 추론,3-1. 디코딩 알고리즘,정의,"거대 언어 모델이 입력에 대해 다음 토큰에 대한 확률 분포를 제공할 때, 이 분포로부터 다음 토큰을 생성하는 알고리즘"
거대 언어 모델의 추론,3-1. 디코딩 알고리즘,Greedy Decoding,"가장 확률이 높은 다음 토큰을 선택하며, 사용하기 쉽지만 최종 응답이 최선이 아닐 수 있음"
거대 언어 모델의 추론,3-1. 디코딩 알고리즘,Beam Search,"확률이 높은 k개(beam size)의 후보를 동시에 고려하여 누적 확률이 높은 문장을 선택하며, 좋은 응답 생성 확률이 높으나 계산 비용이 큼"
거대 언어 모델의 추론,3-1. 디코딩 알고리즘,Sampling,"거대 언어 모델이 제공한 확률을 기준으로 랜덤하게 응답을 생성하며, 다양한 응답 생성이 가능하나 품질이 불안정할 수 있음"
거대 언어 모델의 추론,3-1. 디코딩 알고리즘,Sampling with ""Temperature"",""하이퍼 파라미터 T를 통해 생성된 확률 분포를 임의로 조작하여 창의성과 안정성을 조절함 (T > 1: 확률 분포를 Smooth하게 만들어 다양성 증가)"
거대 언어 모델의 추론,3-1. 디코딩 알고리즘,Top-K Sampling,"확률이 높은 K개의 토큰 중에서만 랜덤하게 샘플링하며, 잡음 단어를 배제하고 품질을 향상시킬 수 있으나 K값이 고정되어 문맥에 따라 불균형해질 수 있음"
거대 언어 모델의 추론,3-1. 디코딩 알고리즘,Top-P Sampling (Nucleus Sampling),"K를 고정하는 대신 누적 확률(P)에 집중하여 K를 자동 조절하며, 확률 누적을 기준으로 하여 품질과 다양성을 균형 있게 맞출 수 있음"
거대 언어 모델의 추론,3-2. 프롬프트 엔지니어링,정의,"원하는 응답을 얻기 위해 모델에 주어지는 입력(프롬프트)을 설계하고 조정하는 기법"
거대 언어 모델의 추론,3-2. 프롬프트 엔지니어링,입력 구성 요소,"지시(instruction)와 예시(few-shot examples)로 구성되며, 어떻게 지시를 주고 예시를 보여주는지가 모델 성능에 큰 영향을 미침"
거대 언어 모델의 추론,3-2. 프롬프트 엔지니어링,Chain-of-Thought (CoT) 프롬프팅,"단순히 질문과 응답을 예시로 활용하는 것을 넘어, 추론(Reasoning) 과정을 예시에 포함하여 더 정확한 정답 생성을 기대할 수 있으며, LLM의 추론 성능을 크게 증가시킴"
거대 언어 모델의 추론,3-2. 프롬프트 엔지니어링,0-shot CoT 프롬프팅,"예시 없이 ""Let's think step by step""과 같은 유인 문장을 통해 모델이 추론을 생성하도록 유도하여 LLM의 추론 성능을 강화함"
거대 언어 모델의 평가와 응용,4-1. 거대 언어 모델의 평가,평가 특징,"특정 태스크에 학습된 기존 AI 모델들과 달리, LLM은 다양한 태스크에 동시 학습되므로, 성능을 올바르게 평가하기 위해서는 다양한 태스크에서의 성능을 종합적으로 판단해야 함"
거대 언어 모델의 평가와 응용,4-1. 거대 언어 모델의 평가,평가 방법 (정답이 정해진 경우),"예측과 정답을 비교하여 일치도(정확도)를 측정함. 예시: MMLU 벤치마크"
거대 언어 모델의 평가와 응용,4-1. 거대 언어 모델의 평가,평가 방법 (정답이 정해지지 않은 경우, 1),"사람이 임의의 정답을 작성하고 이를 모델의 예측과 비교하여 텍스트 간의 유사도(예: ROUGE, 코사인 유사도)를 측정함"
거대 언어 모델의 평가와 응용,4-1. 거대 언어 모델의 평가,평가 방법 (정답이 정해지지 않은 경우, 2),"정답과 무관하게 생성된 텍스트 자체의 품질을 측정함. 예시: Perplexity(PPL)를 사용한 텍스트의 확률적 자연스러움 측정"
거대 언어 모델의 평가와 응용,4-1. 거대 언어 모델의 평가,평가 방법 (정답이 정해지지 않은 경우, 3) LLM-as-judge (G-Eval),"거대 언어 모델(LLM)을 심사관으로 활용하여 생성된 텍스트의 ""상대적 선호""를 평가할 수 있음"
거대 언어 모델의 평가와 응용,4-2. 거대 언어 모델의 응용 및 한계,응용 (1) 멀티모달 파운데이션 모델,"GPT-4o와 같이 이미지, 비디오, 오디오 등의 멀티모달 데이터를 거대 언어 모델이 이해하고 처리할 수 있도록 토큰화 및 학습시킴"
거대 언어 모델의 평가와 응용,4-2. 거대 언어 모델의 응용 및 한계,응용 (2) 합성 데이터 생성,"Self-instruct나 Alpagsus 방법론을 사용하여 사람이 작성한 소량의 데이터를 기반으로 LLM이 대규모 합성 데이터를 생성하여 학습에 활용함"
거대 언어 모델의 평가와 응용,4-2. 거대 언어 모델의 응용 및 한계,한계 (1) 환각 (Hallucination),"사실과 다르거나, 전적으로 지어낸 내용임에도 불구하고 정확한 정보인 것처럼 응답을 생성하는 현상. (RAG(검색 증강 생성)를 통해 해결 가능)"
거대 언어 모델의 평가와 응용,4-2. 거대 언어 모델의 응용 및 한계,한계 (2) 탈옥 (Jailbreaking),"프롬프트 엔지니어링을 통해 거대 언어 모델의 정렬(안전 규칙)을 우회할 수 있는 현상"