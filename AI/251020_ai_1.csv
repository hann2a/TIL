대분류,중분류,소분류,내용,출처
"AI & 기계학습 기초 1","AI, ML, DL의 정의","AI (Artificial Intelligence)","주어진 환경/데이터를 인지·학습·추론하여 목표 달성을 위한 예측·행동 선택·계획을 수행하는 시스템", ""
"AI & 기계학습 기초 1","AI, ML, DL의 정의","ML (Machine Learning)","AI 범주 내에서 데이터로부터 학습하여 목적을 달성하는 접근 방법론", ""
"AI & 기계학습 기초 1","AI, ML, DL의 정의","DL (Deep Learning)","ML 범주 내에서 신경망(Neural Network) 함수를 사용하는 학습 방법론", ""
"AI & 기계학습 기초 1","AI, ML, DL의 정의","AI - ML 예시","규칙 기반 시스템, 휴리스틱 기반(최적화) 알고리즘", ""
"AI & 기계학습 기초 1","데이터 구성 요소","Feature (피처, 특성)","모델이 예측에 사용하는 입력 정보; 예측, 판단의 근거/단서", ""
"AI & 기계학습 기초 1","데이터 구성 요소","Label (라벨, 목표값)","모델이 예측하려는 정답; 학습의 목표", ""
"AI & 기계학습 기초 1","ML 실생활 예시","유튜브 추천 (Feature)","각 영상들의 정보(장르, 크리에이터, 조회수, 좋아요 수 등), 사용자 정보(시청 이력, 구독 채널 등)", ""
"AI & 기계학습 기초 1","ML 실생활 예시","유튜브 추천 (Label)","영상에 대한 사용자 피드백(시청 여부, 좋아요 클릭 여부)", ""
"AI & 기계학습 기초 1","ML 실생활 예시","스팸메일 분류 (Feature)","메일 제목, 발신자, 단어 빈도", ""
"AI & 기계학습 기초 1","ML 실생활 예시","스팸메일 분류 (Label)","스팸/정상", ""
"AI & 기계학습 기초 1","단일 피처 기반 학습","1D 피처 기반 학습","Feature가 하나일 때 머신러닝이 학습하는 가장 단순한 형태 (1차원)", ""
"AI & 기계학습 기초 1","모델과 가설 공간","학습 (Learning)","입력(Feature)에서 출력(Label) 관계를 찾는 과정", ""
"AI & 기계학습 기초 1","모델과 가설 공간","가설 공간 (Hypothesis Space)","관계를 표현할 수 있는 모든 후보 함수들의 모음", ""
"AI & 기계학습 기초 1","모델과 가설 공간","모델 (Model)","가설 공간에 속한 특정 함수 $f$", ""
"AI & 기계학습 기초 1","학습이란","정의","주어진 데이터와 성능 척도를 바탕으로 가설 공간의 후보들 중 최적의 모델을 선택하는 과정", ""
"AI & 기계학습 기초 1","복수 피처 기반 학습","2D 피처 기반 학습","Feature가 2개 이상일 경우의 학습 형태 (예: Income = $f^*$(Years of Education, Seniority) + $\epsilon$)", ""
"AI & 기계학습 기초 1","f(·)를 학습하는 이유","예측","잘 학습된 $f$를 통해 새로운 입력 $X$에서 반응/목표 $Y$를 예측", ""
"AI & 기계학습 기초 1","f(·)를 학습하는 이유","중요 특성 파악","피처 $X$ 중 어떤 특성이 $Y$를 설명하는 데 중요한지 파악", ""
"AI & 기계학습 기초 1","f(·)를 학습하는 이유","해석 가능성","모델의 복잡도에 따라 각 구성요소 $X_j$가 $Y$에 어떻게 영향을 미치는지 이해", ""
"AI & 기계학습 기초 2","지도학습 개념","지도학습 정의","입력(Feature)과 정답(Label)이 쌍으로 있는 데이터로 학습", ""
"AI & 기계학습 기초 2","지도학습 개념","지도학습 목표","새로운 입력에 대해 정답을 잘 예측하는 규칙을 찾는 것 (일반화)", ""
"AI & 기계학습 기초 2","지도학습 종류","회귀 (Regression)","예측값이 연속적인 숫자 (예: 집값, 점수, 온도, 매출액)", ""
"AI & 기계학습 기초 2","지도학습 종류","분류 (Classification)","예측값이 범주 (예: 스팸/정상, 질병 유무, 악성/양성)", ""
"AI & 기계학습 기초 2","회귀 오류 및 설명력","MSE (평균제곱오차)","각 데이터에서 정답과 예측의 평균 제곱 차이값", ""
"AI & 기계학습 기초 2","회귀 오류 및 설명력","$R^2$ (결정계수)","모델이 데이터를 얼마나 설명하는지 나타내는 지표 (0~1 사이, 1에 가까울수록 설명력 높음)", ""
"AI & 기계학습 기초 2","분류 평가 지표","정확도 (Accuracy)","전체 중 맞춘 비율 (불균형 데이터에 한계)", ""
"AI & 기계학습 기초 2","분류 평가 지표","혼동행렬 (Confusion Matrix)","예측과 실제 값의 관계를 행렬 형태로 표현 (분류 문제의 성능 평가 지표)", ""
"AI & 기계학습 기초 2","분류 평가 지표","정밀도 (Precision)","양성이라 판정한 것 중 진짜 양성의 비율", ""
"AI & 기계학습 기초 2","분류 평가 지표","재현율 (Recall/Sensitivity)","진짜 양성 가운데 예측된 양성의 비율", ""
"AI & 기계학습 기초 2","학습의 목적 및 과적합","학습의 목적","테스트 예측(일반화); 처음 보는 데이터에서도 잘 작동해야 함", ""
"AI & 기계학습 기초 2","학습의 목적 및 과적합","오버피팅 (Overfitting)","훈련 데이터의 잡음까지 학습하여 훈련 성능은 높고 테스트 성능이 나빠지는 현상 (모델이 지나치게 복잡)", ""
"AI & 기계학습 기초 2","학습의 목적 및 과적합","언더피팅 (Underfitting)","모델이 너무 단순하거나 학습이 부족하여 중요한 패턴을 놓치는 현상 (훈련 오류와 테스트 오류 모두 큼)", ""
"AI & 기계학습 기초 3","테스트 성능 평가","훈련 오류","모델을 학습시킨 같은 데이터에 적용해 계산한 오류", ""
"AI & 기계학습 기초 3","테스트 성능 평가","테스트 오류","학습에 쓰지 않은 새 관측치에 모델을 적용했을 때의 평균 예측 오류 (일반화 성능 기준)", ""
"AI & 기계학습 기초 3","테스트 성능 평가","재표본화 (Resampling)","데이터를 나눠 여러 번 훈련/평가를 반복해 테스트 오류를 추정하는 대안", ""
"AI & 기계학습 기초 3","검증셋 (Validation Set)","검증셋 방법 (Hold-out)","가용 샘플을 훈련셋과 검증셋으로 무작위 분할", ""
"AI & 기계학습 기초 3","검증셋 (Validation Set)","검증셋의 한계","전체 데이터를 학습했을 때보다 성능이 낮게 추정될 수 있음 (테스트 오류 과대 추정)", ""
"AI & 기계학습 기초 3","K-겹 교차검증","K-fold Cross-Validation","데이터 전체를 크기 동일한 K개 폴드(그룹)로 무작위 분할하여 K번 반복 후 평균 오류로 테스트 오류를 추정", ""
"AI & 기계학습 기초 3","K-겹 교차검증","LOOCV (Leave-One-Out)","K=n일 경우의 교차검증 (관측치 하나만 제외한 나머지를 훈련셋으로 사용)", ""
"AI & 기계학습 기초 3","K-겹 교차검증","장점","데이터 활용성을 높여 일반화 성능을 더 정확히 추정", ""
"AI & 기계학습 기초 4","비지도 학습","비지도 학습 정의","레이블(정답)이 없는 데이터를 통해 데이터의 구조·패턴·집단(잠재 서브그룹)을 찾아내는 학습", ""
"AI & 기계학습 기초 4","비지도 학습","대표 과제","군집화(Clustering), 차원 축소(PCA), 밀도 추정/이상치 탐지", ""
"AI & 기계학습 기초 4","클러스터링","정의","데이터 안에서 하위 집단(클러스터)을 찾는 기법들의 총칭", ""
"AI & 기계학습 기초 4","클러스터링","목표","집단 내부는 서로 유사, 집단 간은 서로 상이하도록 데이터 분할", ""
"AI & 기계학습 기초 4","K-means 클러스터링","특징","클러스터 수 K를 미리 지정해 분할", ""
"AI & 기계학습 기초 4","K-means 클러스터링","핵심 아이디어","클러스터 내부 변동(Within-Cluster Variation)의 합이 최소가 되도록 분할", ""
"AI & 기계학습 기초 4","계층적 군집","특징","K를 사전에 고정하지 않고 전체 구조를 덴드로그램으로 제공 (상향식 병합)", ""
"AI & 기계학습 기초 4","계층적 군집","링크 유형: Single","두 클러스터 내 데이터 쌍별 거리 중 **최소값**을 군집 간 거리로 사용", ""
"AI & 기계학습 기초 4","계층적 군집","링크 유형: Complete","두 클러스터 내 데이터 쌍별 거리 중 **최대값**을 군집 간 거리로 사용", ""
"AI & 기계학습 기초 4","계층적 군집","링크 유형: Average","두 클러스터 내 데이터 쌍별 거리의 **평균**을 군집 간 거리로 사용", ""
"AI & 기계학습 기초 4","클러스터링 시 주의점","스케일링 필요 여부","변수 단위 차이가 클 경우 스케일링(표준화) 필요", ""